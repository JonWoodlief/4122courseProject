{"status":"OK","data":{"id":60626,"identifier":"DVN/BYPZ8N","persistentUrl":"https://doi.org/10.7910/DVN/BYPZ8N","protocol":"doi","authority":"10.7910","publisher":"Harvard Dataverse","publicationDate":"2013-05-21","storageIdentifier":"s3://dvn-cloud:1902.1/21521","latestVersion":{"id":62154,"storageIdentifier":"s3://dvn-cloud:1902.1/21521","versionNumber":2,"versionMinorNumber":0,"versionState":"RELEASED","versionNote":"","distributionDate":"2013","productionDate":"Production Date","lastUpdateTime":"2013-05-31T05:59:16Z","releaseTime":"2013-05-31T00:00:00Z","createTime":"2013-05-24T04:35:23Z","license":"CC0","termsOfUse":"CC0 Waiver","metadataBlocks":{"citation":{"displayName":"Citation Metadata","fields":[{"typeName":"title","multiple":false,"typeClass":"primitive","value":"National Health Interview Survey (NHIS)"},{"typeName":"author","multiple":true,"typeClass":"compound","value":[{"authorName":{"typeName":"authorName","multiple":false,"typeClass":"primitive","value":"Damico, Anthony"}}]},{"typeName":"datasetContact","multiple":true,"typeClass":"compound","value":[{"datasetContactEmail":{"typeName":"datasetContactEmail","multiple":false,"typeClass":"primitive","value":"ajdamico@gmail.com"}}]},{"typeName":"dsDescription","multiple":true,"typeClass":"compound","value":[{"dsDescriptionValue":{"typeName":"dsDescriptionValue","multiple":false,"typeClass":"primitive","value":"<h3 class=\"post-title entry-title\" itemprop=\"name\"> analyze the national health interview survey (nhis) with r </h3> the national health interview survey (nhis) is a household survey about health status and utilization.   each annual data set can be used to examine the disease burden and access to care that individuals and families are currently experiencing across the country.   check out <a href=\"http://en.wikipedia.org/wiki/National_Health_Interview_Survey\">the wikipedia article</a> (ohh hayy\ni wrote that) for more detail about its current and potential uses.   if you're cooking up a health-related analysis that doesn't need medical expenditures or monthly health insurance coverage, look at nhis before the medical expenditure panel survey (it's sample is twice as big).\n<a href=\"http://www.cdc.gov/\">the centers for disease control and prevention (cdc)</a> has been keeping nhis real since 1957, and the scripts below automate the download, importation, and analysis of every file back to 1963.<br /> <br /> what happened in 1997, you ask?    scientists cloned <a href=\"http://en.wikipedia.org/wiki/Dolly_%28sheep%29\">dolly the sheep</a>, clinton started his second term, and the national health interview survey underwent its most recent major questionnaire re-design.\nhere's how all the moving parts work:<br /> <ul> <li>a person-level file (personsx) that merges onto other files using unique household (hhx), family (fmx), and person (fpx) identifiers.   [note to data historians: prior to 2004, person number was (px) and unique within each household.]   this file includes the complex sample survey variables needed to construct a taylor-series linearization design, and should be used if your analysis doesn't require variables from the sample adult or sample c\nhild files.   this survey setup generalizes to the noninstitutional, non-active duty military population.\n</li> <li>a family-level file that merges onto other files using unique household (hhx) and family (fmx) identifiers.</li> <li>a household-level file that merges onto other files using the unique household (hhx) identifier.</li> <li>a sample adult file that includes questions asked of only one adult within each household (selected at random) - a subset of the main person-level file.   hhx, fmx, and fpx identifiers will merge with each of the files above, but since not every adult gets asked thes\ne questions, this file contains its own set of weights: wtfa_sa instead of wtfa.   you can merge on whatever other variables you need from the three files above, but if your analysis requires any variables from the sample adult questionnaire, you can't use records in the person-level file that aren't also in the sample adult file (a big sample size cut).   this survey setup generalizes to the noninstitutional, non-active duty military\n<i>adult</i> population.</li> <li>a sample child file that includes questions asked of only one child within each household (if available, and also selected at random) - another subset of the main person-level file.   same deal as the sample adult description, except use wtfa_sc instead of wtfa oh yeah and this one generalizes to the <i>child</i> population.</li> <li>five imputed income files.   if you want income and/or poverty variables incorporated into any part of your analysis, you'll need\nthese puppies.   the replication example below uses these, but if that's impenetrable, post in the comments describing where you get stuck.\n</li> <li>some injury stuff and other miscellanea that varies by year.   if anyone uses this, please share your experience.</li> </ul> <br /> if you<span class=\"Apple-converted-space\"> use anything more than the personsx file alone, you'll need to </span><a href=\"http://www.screenr.com/Znd8\">merge</a> some tables together.   make sure you understand the difference between setting the parameter all = TRUE versus all = FALSE -- not everyone in the personsx file has a record in the samadult and sam\nchild files.<br /> <br /> this new github repository contains four scripts:<br /> <br /> <b>1963-2011 - download all microdata.R</b><br /> <ul> <li>loop through every year and download every file hosted on the cdc's nhis ftp site</li> <li>import each file into r with <a href=\"http://cran.r-project.org/web/packages/SAScii/index.html\">SAScii</a></li> <li>save each file as an<span class=\"Apple-converted-space\">  </span><a href=\"http://stat.ethz.ch/R-manual/R-patched/library/base/html/save.html\">r d\nata file</a><span class=\"Apple-converted-space\">  </span>(.rda)</li> <li>download all the documentation into the year-specific directory</li> </ul> <br /> <b>2011 personsx - analyze.R</b><b>  </b><br /> <ul> <li>load the <a href=\"http://stat.ethz.ch/R-manual/R-devel/library/base/html/load.html\">r data file</a> (.rda) created by the download script (above)</li> <li>set up a taylor-series linearization survey design outlined on <a href=\"http://www.cdc.gov/nchs/data/nhis/2006var.pdf\">page 6</a><a h\nref=\"ftp://ftp.cdc.gov/pub/health_statistics/nchs/dataset_documentation/nhis/2011/srvydesc.pdf\"> of this survey document\n</a></li> <li>perform a smattering of analysis examples</li> </ul> <br /> <b>2011 personsx plus samadult with multiple imputation - analyze.R</b><br /> <ul> <li>load the personsx and samadult <a href=\"http://stat.ethz.ch/R-manual/R-devel/library/base/html/load.html\">r data files</a> (.rda) created by the download script (above)</li> <li>merge the personsx and samadult files, highlighting how to conduct analyses that need both </li> <li>create tandem survey designs for both personsx-only and merg\ned personsx-samadult files</li> <li>perform just a touch of analysis examples</li> <li>load and loop through the five imputed income files, tack them onto the personsx-samadult file</li> <li>conduct a poverty recode or two</li> <li>analyze the multiply-imputed survey design object, just like mom used to analyze</li> </ul> <br /> <b>replicate cdc tecdoc - 2000 multiple imputation.R</b><br /> <ul> <li>download and import the nhis 2000 personsx and imputed income files, using <a href=\"http://cran.r\n-project.org/web/packages/SAScii/index.html\">SAScii</a> and this <a href=\"https://github.com/ajdamico/usgsd/blob/master/National%20Health%20Interview%20Survey/INCMIMP2000.sas\">imputed income sas importation script</a> (no longer hosted on the cdc's nhis ftp site).</li> <li>loop  through each of the five imputed income files, merging each to the  personsx file and performing the same set of variable recodes</li> <li>construct a multiply-imputed survey design object</li> <li>analyze the multiply-i\nmputed survey design object to generate <a href=\"http://www.cdc.gov/nchs/data/nhis/tecdoc_2010.pdf\">pdf page 60 of this technical document</a></li> </ul> <br /> <br /> <a href=\"https://github.com/ajdamico/usgsd/tree/master/National%20Health%20Interview%20Survey\">click here to view these four scripts</a><br /> <br /> <br /> for more detail about the national health interview survey (nhis), visit:  <br /> <ul> <li>the centers for disease control and prevention's <a href=\"http://www.cdc.gov/nchs/nh\nis.htm\">national health interview survey homepage</a> </li> <li>the national health interview survey <a href=\"http://en.wikipedia.org/wiki/National_Health_Interview_Survey\">according to wikipedia</a></li> <li>the minnesota population data center's <a href=\"http://www.ihis.us/ihis/index.shtml\">harmonized national health interview survey homepage</a></li> </ul> <br /> notes:<br /> <br /> the national health interview survey is the first and only us government survey data set to include any <a href\n=\"http://www.cdc.gov/nchs/data/nhis/2006var.pdf\">r syntax examples (page 6)\n</a>.   an inspiration.<br /> <br /> the cdc often includes supplemental survey questions in nhis.   <a href=\"http://www.cdc.gov/nchs/nhis/supplements_cosponsors.htm\">check 'em out</a>.<br /> <br /> unless specified by the question's phrasing, most nhis variables should be treated as point-in-time, as opposed to either <i>annualized</i> or <i>ever during the year</i>.   this distinction is particularly important for health insurance coverage.   think about these three statistics --<br /> <ul> <l\ni>the number of americans who won't have health insurance at least once during this year\n</li> <li>the number of americans without health insurance right now</li> <li>the number of americans who won't ever have health insurance during this year</li> </ul> -- the number of americans without health insurance right now is the point-in-time variable, smaller than the <i>at least once</i> number but larger than the <i>ever</i> number.<br /> <br /> <br /> confidential to sas, spss, stata, and sudaan users: why are you still rocking out on that cassette tape after we've designed the ipod?\ntime to transition to r.   :D"}}]},{"typeName":"producer","multiple":true,"typeClass":"compound","value":[{"producerName":{"typeName":"producerName","multiple":false,"typeClass":"primitive","value":"Anthony Damico"},"producerURL":{"typeName":"producerURL","multiple":false,"typeClass":"primitive","value":"http://www.asdfree.com/"}}]},{"typeName":"distributor","multiple":true,"typeClass":"compound","value":[{"distributorName":{"typeName":"distributorName","multiple":false,"typeClass":"primitive","value":"IQSS Dataverse Network"},"distributorURL":{"typeName":"distributorURL","multiple":false,"typeClass":"primitive","value":"http://dvn.iq.harvard.edu"},"distributorLogoURL":{"typeName":"distributorLogoURL","multiple":false,"typeClass":"primitive","value":"http://dvn.iq.harvard.edu/images/iqss-logo-background.png"}}]},{"typeName":"distributionDate","multiple":false,"typeClass":"primitive","value":"2013"},{"typeName":"dateOfDeposit","multiple":false,"typeClass":"primitive","value":"2013"}]}},"files":[]}}}