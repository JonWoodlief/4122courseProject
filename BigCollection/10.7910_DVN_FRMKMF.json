{"status":"OK","data":{"id":60643,"identifier":"DVN/FRMKMF","persistentUrl":"https://doi.org/10.7910/DVN/FRMKMF","protocol":"doi","authority":"10.7910","publisher":"Harvard Dataverse","publicationDate":"2013-05-21","storageIdentifier":"s3://dvn-cloud:1902.1/21526","latestVersion":{"id":62179,"storageIdentifier":"s3://dvn-cloud:1902.1/21526","versionNumber":2,"versionMinorNumber":0,"versionState":"RELEASED","versionNote":"","distributionDate":"2013","productionDate":"Production Date","lastUpdateTime":"2013-05-31T06:04:56Z","releaseTime":"2013-05-31T00:00:00Z","createTime":"2013-05-24T04:44:48Z","license":"CC0","termsOfUse":"CC0 Waiver","metadataBlocks":{"citation":{"displayName":"Citation Metadata","fields":[{"typeName":"title","multiple":false,"typeClass":"primitive","value":"Survey of Consumer Finances (SCF)"},{"typeName":"author","multiple":true,"typeClass":"compound","value":[{"authorName":{"typeName":"authorName","multiple":false,"typeClass":"primitive","value":"Damico, Anthony"}}]},{"typeName":"datasetContact","multiple":true,"typeClass":"compound","value":[{"datasetContactEmail":{"typeName":"datasetContactEmail","multiple":false,"typeClass":"primitive","value":"ajdamico@gmail.com"}}]},{"typeName":"dsDescription","multiple":true,"typeClass":"compound","value":[{"dsDescriptionValue":{"typeName":"dsDescriptionValue","multiple":false,"typeClass":"primitive","value":"<h3 class=\"post-title entry-title\" itemprop=\"name\"> analyze the survey of consumer finances (scf) with r </h3> the survey of consumer finances (scf) tracks the wealth of american families.  every three years, more than five thousand households answer a battery of questions about income, net worth, credit card debt, pensions, mortgages, even the lease on their cars.  plenty of surveys collect annual income, only the survey of consumer finances captures such detailed asset data.  responses are at\nthe primary economic unit-level (peu) - the economically dominant, financially interdependent family members within a sampled household.\n<a href=\"http://www.norc.uchicago.edu/\">norc at the university of chicago</a> administers the data collection,  but <a href=\"http://www.federalreserve.gov/default.htm\">the board of governors of the federal reserve</a>  pay the bills and therefore call the shots.<br /> <br /> if you were so brazen as to open up the microdata and run a simple weighted median, you'd get the wrong answer.  the five to six thousand respondents actually gobble up twenty-five to thirty thousand records in the final pub\nlic use files.  why oh why?  well, those tables contain not one, not two, but five records for each peu.  wherever missing,\n<a href=\"http://www.federalreserve.gov/econresdata/scf/files/impute98.pdf\">these data are multiply-imputed</a>, meaning answers to the same question for the same household might vary across implicates.  each analysis must account for all that, lest your <a href=\"http://www.federalreserve.gov/econresdata/scf/scf_faqs.htm#q7\">confidence intervals be too tight</a>.  to calculate the correct statistics, you'll need to break the single file into five, necessarily complicating your life.  this can be\naccomplished with the `meanit` sas macro buried in <a href=\"http://www.federalreserve.gov/econresdata/scf/files/codebk2004.txt\">the 2004 scf codebook</a> (search for `meanit` - you'll need <a href=\"http://support.sas.com/rnd/app/da/iml.html\">the sas iml add-on</a>).  or you might blow the dust off <a href=\"http://hec.osu.edu/people/shanna/imput.htm\">this website</a> referred to in <a href=\"http://www.federalreserve.gov/econresdata/scf/files/codebk2010.txt\">the 2010 codebook</a> as the home of an\nalternative multiple imputation technique, but all i found were broken links.  perhaps it's time for plan c, and by c, i mean free.  read the imputation section of\n<a href=\"http://www.federalreserve.gov/econresdata/scf/files/codebk2010.txt\">the latest codebook</a> (search for `imputation`), then give these scripts a whirl.  they've got that new r smell.<br /> <br /> the lion's share of the respondents in the survey of consumer finances get drawn from a pretty standard sample of american dwellings - no nursing homes, no active-duty military.  then there's this secondary sample of richer households to even out the statistical noise at the higher end of the i\nncome and assets spectrum.  <a href=\"http://www.federalreserve.gov/econresdata/scf/files/panelwgtdoc.txt\">you can read more if you like</a>, but at the end of the day the weights just generalize to civilian, non-institutional american households.  one last thing before you start your engine: read <a href=\"http://legacy.ehe.osu.edu/cs/scf/cmacci98.htm\">everything you always wanted to know about the scf</a>.  my favorite part of that title is the word always.  this new github repository contains t\nhree scripts:<br /> <br /> <br /> <b>1989-2010 download all microdata.R</b><br /> <ul> <li>initiate a function to download and import any survey of consumer finances zipped stata file (.dta)</li> <li>loop through each year specified by the user (starting at <a href=\"http://www.federalreserve.gov/econresdata/scf/scf_1989.htm\">the 1989 re-vamp</a>) to download the main, <a href=\"http://www.federalreserve.gov/econresdata/scf/scf_2010survey.htm#STATADATEX\">extract</a>, and <a href=\"http://www.federa\nlreserve.gov/econresdata/scf/scf_2010weight.htm\">replicate weight\n</a> files, then <a href=\"http://www.screenr.com/5gH8\">import each into r</a></li> <li>break the main file into five implicates (each containing one record per peu) and merge the appropriate extract data onto each implicate</li> <li>save the five implicates and replicate weights to an <a href=\"http://stat.ethz.ch/R-manual/R-patched/library/base/html/save.html\">r data file</a> (.rda) for rapid future loading</li> </ul> <br /> <b>2010 analysis examples.R</b><br /> <ul> <li>prepare two <a href=\"htt\nps://github.com/ajdamico/usgsd/blob/master/Survey%20of%20Consumer%20Finances/scf.survey.R\">survey of consumer finances-flavored\n</a> multiply-imputed survey analysis functions</li> <li>load the <a href=\"http://stat.ethz.ch/R-manual/R-devel/library/base/html/load.html\">r data files</a> (.rda) necessary to create a <a href=\"http://faculty.washington.edu/tlumley/survey/svymi.html\">multiply-imputed</a>, <a href=\"http://faculty.washington.edu/tlumley/survey/html/svrepdesign.html\">replicate-weighted</a> survey design</li> <li>demonstrate <a href=\"http://www.screenr.com/2Cs8\">how to access the properties</a> of a multiply-imput\ned survey design object </li> <li>cook up some descriptive statistics and export examples, calculated with scf-centric variance quirks</li> <li>run a quick t-test and regression, but only because you asked nicely</li> </ul> <br /> <b>replicate FRB SAS output.R</b><br /> <ul> <li>reproduce <a href=\"https://github.com/ajdamico/usgsd/blob/master/Survey%20of%20Consumer%20Finances/SCF%20PUF%20Net%20Worth%20Statistics%20and%20Standard%20Errors%20from%20FRB.pdf?raw=true\">each and every statistic</a> pr\novided by the friendly folks at the federal reserve</li> <li>create a <a href=\"http://faculty.washington.edu/tlumley/survey/svymi.html\">multiply-imputed</a>, <a href=\"http://faculty.washington.edu/tlumley/survey/html/svrepdesign.html\">replicate-weighted</a> survey design object</li> <li>re-reproduce (and yes, i said/meant what i meant/said) each of those statistics, now using the multiply-imputed <a href=\"http://faculty.washington.edu/tlumley/survey/html/svrepdesign.html\">survey design object</a\n> to highlight the statistically-theoretically-irrelevant differences\n</li> </ul> <br /> <br /> <br /> <a href=\"https://github.com/ajdamico/usgsd/tree/master/Survey%20of%20Consumer%20Finances\">click here to view these three scripts</a><br /> <br /> <br /> <br /> for more detail about the survey of consumer finances (scf), visit:<br /> <br /> <ul> <li>the federal reserve board of governors' <a href=\"http://www.federalreserve.gov/econresdata/scf/scfindex.htm\">survey of consumer finances homepage </a></li> <li><a href=\"http://www.federalreserve.gov/econresdata/scf/fi\nles/2010_SCF_Chartbook.pdf\">the latest scf chartbook</a>, to browse what's possible.  (spoiler alert: everything.)</li> <li>the survey of consumer finances <a href=\"http://en.wikipedia.org/wiki/Survey_of_Consumer_Finances\">wikipedia entry</a></li> <li>the official <a href=\"http://www.federalreserve.gov/econresdata/scf/scf_faqs.htm\">frequently asked questions</a></li> </ul> <br /> notes:<br /> <br /> nationally-representative statistics on the financial health, wealth, and assets of american hous\neholds might not be monopolized by the survey of consumer finances, but there isn't much competition aside from\n<a href=\"http://www.census.gov/sipp/top_mod/2008/quests/2008w4tm.pdf\">the assets topical module</a> of the <a href=\"http://www.census.gov/sipp/\">survey of income and program participation (sipp)</a>.  on one hand, the scf <a href=\"http://www.federalreserve.gov/econresdata/scf/files/2010_scfoutline.pdf\">interview questions</a> contain more detail than sipp.  on the other hand, scf's smaller sample precludes analyses of acute subpopulations.  and for any three-handed martians in the audience, ther\ne's also <a href=\"http://lmgtfy.com/?q=scf+sipp+asset\">a few biases</a> between these two data sources that you ought to consider.<br /> <br /> the survey methodologists at the federal reserve take their job seriously, as evidenced by <a href=\"http://www.federalreserve.gov/econresdata/scf/scf_workingpapers.htm\">this working paper trail</a>.  write a thank-you in their <a href=\"http://www.federalreserve.gov/forms/scf_guestbook.aspx\">guestbook</a>.  one can never receive enough of those.<br /> <br\n/> <br /> confidential  to sas, spss, stata, and sudaan users: the eighties called.  they want their statistical languages back.  time to transition to r.  :D"}}]},{"typeName":"producer","multiple":true,"typeClass":"compound","value":[{"producerName":{"typeName":"producerName","multiple":false,"typeClass":"primitive","value":"Anthony Damico"},"producerURL":{"typeName":"producerURL","multiple":false,"typeClass":"primitive","value":"http://www.asdfree.com/"}}]},{"typeName":"distributor","multiple":true,"typeClass":"compound","value":[{"distributorName":{"typeName":"distributorName","multiple":false,"typeClass":"primitive","value":"IQSS Dataverse Network"},"distributorURL":{"typeName":"distributorURL","multiple":false,"typeClass":"primitive","value":"http://dvn.iq.harvard.edu"},"distributorLogoURL":{"typeName":"distributorLogoURL","multiple":false,"typeClass":"primitive","value":"http://dvn.iq.harvard.edu/images/iqss-logo-background.png"}}]},{"typeName":"distributionDate","multiple":false,"typeClass":"primitive","value":"2013"},{"typeName":"dateOfDeposit","multiple":false,"typeClass":"primitive","value":"2013"}]}},"files":[]}}}